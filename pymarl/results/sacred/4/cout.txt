[INFO 05:38:54] pymarl Running command 'my_main'
[INFO 05:38:54] pymarl Started run with ID "4"
[DEBUG 05:38:54] pymarl Starting Heartbeat
[DEBUG 05:38:54] my_main Started
[INFO 05:38:54] my_main Experiment Parameters:
[INFO 05:38:54] my_main 

{   'action_selector': 'epsilon_greedy',
    'agent': 'rnn_fast',
    'agent_output_type': 'q',
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': False,
    'buffer_size': 5000,
    'burn_in_period': 32,
    'checkpoint_path': '',
    'critic_lr': 0.0005,
    'curiosity_decay': True,
    'curiosity_decay_cycle': 5000,
    'curiosity_decay_rate': 0.9,
    'curiosity_decay_stop': 0.01,
    'curiosity_scale': 0.2,
    'double_q': True,
    'emdqn_buffer_size': 1000000,
    'emdqn_latent_dim': 4,
    'emdqn_loss_weight': 0.001,
    'env': 'stag_hunt',
    'env_args': {   'agent_move_block': [   0,
                                            1,
                                            2],
                    'agent_obs': [   2,
                                     2],
                    'capture_action': True,
                    'capture_action_conditions': [   2,
                                                     1],
                    'capture_conditions': [   0,
                                              1],
                    'capture_freezes': True,
                    'capture_terminal': False,
                    'directed_cone_narrow': True,
                    'directed_exta_actions': True,
                    'directed_observations': False,
                    'episode_limit': 200,
                    'intersection_global_view': False,
                    'intersection_unknown': False,
                    'map_name': 'origin',
                    'miscapture_punishment': -2,
                    'mountain_agent_row': -1,
                    'mountain_slope': 0.0,
                    'mountain_spawn': False,
                    'n_agents': 8,
                    'n_hare': 0,
                    'n_stags': 8,
                    'observe_ids': False,
                    'observe_one_hot': False,
                    'observe_state': False,
                    'observe_walls': False,
                    'p_hare_rest': 0.0,
                    'p_stags_rest': 0.0,
                    'prevent_cannibalism': True,
                    'print_caught_prey': False,
                    'print_frozen_agents': False,
                    'random_ghosts': False,
                    'random_ghosts_indicator': False,
                    'random_ghosts_mul': -1,
                    'random_ghosts_prob': 0.5,
                    'remove_frozen': True,
                    'reward_collision': 0,
                    'reward_hare': 1,
                    'reward_stag': 10,
                    'reward_time': 0,
                    'seed': 671929246,
                    'state_as_graph': False,
                    'toroidal': False,
                    'world_shape': [   10,
                                       10]},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'gamma': 0.9,
    'grad_norm_clip': 10,
    'is_batch_rl': False,
    'is_from_start': True,
    'is_prioritized_buffer': True,
    'is_save_buffer': False,
    'joint_random_policy_eps': 0.0,
    'label': 'default_label',
    'learner': 'fast_QLearner',
    'learner_log_interval': 2000,
    'load_buffer_id': 0,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 2000,
    'lr': 0.0005,
    'mac': 'fast_mac',
    'mixer': 'vdn',
    'name': 'EMC_toygame',
    'num_circle': 1,
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'predict_vdn_target': True,
    'prioritized_buffer_alpha': 0.5,
    'q_loss_weight': 1,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'runner': 'episode',
    'runner_log_interval': 2000,
    'save_buffer': False,
    'save_buffer_cycle': 500,
    'save_buffer_id': 0,
    'save_buffer_interval': 1000,
    'save_buffer_path': './results/heatmap/heatmap_buffer_0816/',
    'save_buffer_size': 10000,
    'save_model': True,
    'save_model_interval': 200000,
    'save_replay': False,
    'seed': 671929246,
    'soft_update_tau': 0.005,
    't_max': 1100000,
    'target_update_interval': 200,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 16,
    'use_cuda': True,
    'use_double_predict': False,
    'use_emdqn': False,
    'use_qtotal_td': False,
    'use_tensorboard': True,
    'vdn_soft_update': True}

[INFO 05:38:54] my_main saving tb_logs to results/tb_logs/stag_hunt/origin/EMC_toygame__2022-04-10_05-38-54
[INFO 05:38:56] my_main Beginning training for 1100000 timesteps
/home/lych/IJCAI22/EMC/pymarl/src/components/episode_buffer.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  v = th.tensor(v, dtype=dtype, device=self.device)
[INFO 05:38:57] my_main t_env: 200 / 1100000
[INFO 05:38:57] my_main Estimated time left: 2 minutes, 5 seconds. Time passed: 1 seconds
[INFO 05:39:16] my_main Saving models to results/models/EMC_toygame__2022-04-10_05-38-54/200
[INFO 05:39:26] my_main Recent Stats | t_env:       2000 | Episode:       10
ep_length_mean:          200.0000	episode_limit_mean:        1.0000	epsilon:                   1.0000	num_circle:                1.0000
return_mean:             -90.0000	return_std:                0.0000	test_ep_length_mean:     200.0000	test_episode_limit_mean:   1.0000
test_return_mean:         -0.2500	test_return_std:           0.9682	
[INFO 05:39:38] my_main Recent Stats | t_env:       4000 | Episode:       20
ep_length_mean:          200.0000	episode_limit_mean:        1.0000	epsilon:                   0.9620	num_circle:                1.0000
return_mean:             -95.5000	return_std:               12.9942	test_ep_length_mean:     200.0000	test_episode_limit_mean:   1.0000
test_return_mean:         -0.2500	test_return_std:           0.9682	
[INFO 05:39:49] my_main Recent Stats | t_env:       6000 | Episode:       30
ep_length_mean:          200.0000	episode_limit_mean:        1.0000	epsilon:                   0.9240	num_circle:                1.0000
return_mean:             -96.0667	return_std:               20.5032	test_ep_length_mean:     200.0000	test_episode_limit_mean:   1.0000
test_return_mean:         -0.2500	test_return_std:           0.9682	
[INFO 05:40:01] my_main Recent Stats | t_env:       8000 | Episode:       40
curiosity_decay_cycle:   5000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0100	curiosity_scale:           0.1800
ep_length_mean:          200.0000	episode_limit_mean:        1.0000	epsilon:                   0.8860	extrinsic rewards:        -0.4681
grad_norm:                 1.4919	hit_prob:                  0.2897	loss:                      1.1973	num_circle:                1.0000
q_taken_mean:              0.0520	return_mean:             -92.9500	return_std:               21.7602	target_mean:               0.0554
td_error_abs:              0.7682	test_ep_length_mean:     200.0000	test_episode_limit_mean:   1.0000	test_return_mean:         -0.2500
test_return_std:           0.9682	vdn extrinsic rewards:    -0.4681	vdn grad_norm:             2.5580	vdn hit_prob:              0.2897
vdn intrinsic rewards:     0.2584	vdn loss:                  1.2520	vdn prediction loss:       1.2919	vdn q_taken_mean:          0.0520
vdn target_mean:           0.0231	vdn td_error_abs:          0.6177	
[INFO 05:40:13] my_main Recent Stats | t_env:      10000 | Episode:       50
curiosity_decay_cycle:   5000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0100	curiosity_scale:           0.1800
ep_length_mean:          200.0000	episode_limit_mean:        1.0000	epsilon:                   0.8480	extrinsic rewards:        -0.4391
grad_norm:                 1.5006	hit_prob:                  0.2944	loss:                      0.9703	num_circle:                1.0000
q_taken_mean:              0.0298	return_mean:             -87.7600	return_std:               22.0325	target_mean:               0.0355
td_error_abs:              0.6130	test_ep_length_mean:     200.0000	test_episode_limit_mean:   1.0000	test_return_mean:         -0.2500
test_return_std:           0.9682	vdn extrinsic rewards:    -0.4391	vdn grad_norm:             5.8512	vdn hit_prob:              0.2919
vdn intrinsic rewards:     0.2211	vdn loss:                  1.1417	vdn prediction loss:       1.1567	vdn q_taken_mean:          0.0558
vdn target_mean:           0.0046	vdn td_error_abs:          0.6351	
[INFO 05:40:14] my_main t_env: 10200 / 1100000
[INFO 05:40:14] my_main Estimated time left: 2 hours, 19 minutes, 37 seconds. Time passed: 1 minutes, 18 seconds
