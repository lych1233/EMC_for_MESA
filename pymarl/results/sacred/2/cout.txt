[INFO 05:35:03] pymarl Running command 'my_main'
[INFO 05:35:03] pymarl Started run with ID "2"
[DEBUG 05:35:03] pymarl Starting Heartbeat
[DEBUG 05:35:03] my_main Started
[INFO 05:35:03] my_main Experiment Parameters:
[INFO 05:35:03] my_main 

{   'action_selector': 'epsilon_greedy',
    'agent': 'rnn_fast',
    'agent_output_type': 'q',
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': False,
    'buffer_size': 5000,
    'burn_in_period': 32,
    'checkpoint_path': '',
    'critic_lr': 0.0005,
    'curiosity_decay': True,
    'curiosity_decay_cycle': 5000,
    'curiosity_decay_rate': 0.9,
    'curiosity_decay_stop': 0.01,
    'curiosity_scale': 0.2,
    'demo_interval': 1000,
    'double_q': True,
    'emdqn_buffer_size': 1000000,
    'emdqn_latent_dim': 4,
    'emdqn_loss_weight': 0.001,
    'env': 'gridworld',
    'env_args': {   'episode_limit': 30,
                    'input_cols': 12,
                    'input_rows': 11,
                    'map_name': 'reversed',
                    'noise': False,
                    'noise_num': 10,
                    'path': None,
                    'penalty': True,
                    'penalty_amount': 2,
                    'seed': 837090238},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'gamma': 0.9,
    'grad_norm_clip': 10,
    'is_batch_rl': False,
    'is_from_start': True,
    'is_prioritized_buffer': True,
    'is_save_buffer': False,
    'joint_random_policy_eps': 0.0,
    'label': 'default_label',
    'learner': 'fast_QLearner',
    'learner_log_interval': 1000,
    'load_buffer_id': 0,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 1000,
    'lr': 0.0005,
    'mac': 'fast_mac',
    'mixer': 'vdn',
    'name': 'EMC_toygame',
    'num_circle': 1,
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'predict_vdn_target': True,
    'prioritized_buffer_alpha': 0.5,
    'q_loss_weight': 1,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'runner': 'episode',
    'runner_log_interval': 1000,
    'save_buffer': False,
    'save_buffer_cycle': 500,
    'save_buffer_id': 0,
    'save_buffer_interval': 1000,
    'save_buffer_path': './results/heatmap/heatmap_buffer_0816/',
    'save_buffer_size': 10000,
    'save_model': False,
    'save_model_interval': 20000,
    'save_replay': False,
    'seed': 837090238,
    'soft_update_tau': 0.005,
    't_max': 505000,
    'target_update_interval': 200,
    'test_greedy': True,
    'test_interval': 1000,
    'test_nepisode': 30,
    'use_cuda': True,
    'use_double_predict': False,
    'use_emdqn': False,
    'use_qtotal_td': False,
    'use_tensorboard': True,
    'vdn_soft_update': True}

[INFO 05:35:03] my_main saving tb_logs to results/tb_logs/gridworld/reversed/EMC_toygame__2022-04-10_05-35-03
[INFO 05:35:05] my_main Beginning training for 505000 timesteps
/home/lych/IJCAI22/EMC/pymarl/src/components/episode_buffer.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  v = th.tensor(v, dtype=dtype, device=self.device)
[INFO 05:35:05] my_main t_env: 30 / 505000
[INFO 05:35:05] my_main Estimated time left: 22 seconds. Time passed: 0 seconds
[INFO 05:35:07] my_main Recent Stats | t_env:       1020 | Episode:       34
battle_won_mean:           0.0000	curiosity_decay_cycle:   5000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0100
curiosity_scale:           0.2000	ep_length_mean:           30.0000	epsilon:                   1.0000	extrinsic rewards:        -0.0125
grad_norm:                 2.5595	hit_prob:                  0.2474	loss:                      0.8222	num_circle:                1.0000
q_taken_mean:             -0.0775	return_mean:               0.0000	return_std:                0.0000	target_mean:               0.3617
td_error_abs:              0.8915	test_battle_won_mean:      0.0000	test_ep_length_mean:      30.0000	test_return_mean:          0.0000
test_return_std:           0.0000	vdn extrinsic rewards:    -0.0125	vdn grad_norm:             0.7588	vdn hit_prob:              0.2474
vdn intrinsic rewards:     0.6376	vdn loss:                  0.1089	vdn prediction loss:       3.1882	vdn q_taken_mean:         -0.0775
vdn target_mean:           0.0429	vdn td_error_abs:          0.2666	
[INFO 05:35:07] my_main t_env: 1050 / 505000
[INFO 05:35:07] my_main Estimated time left: 23 minutes, 3 seconds. Time passed: 2 seconds
[INFO 05:35:11] my_main Recent Stats | t_env:       2040 | Episode:       68
battle_won_mean:           0.0000	curiosity_decay_cycle:   5000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0100
curiosity_scale:           0.2000	ep_length_mean:           30.0000	epsilon:                   0.9806	extrinsic rewards:        -0.0156
grad_norm:                 1.4626	hit_prob:                  0.2505	loss:                      0.4483	num_circle:                1.0000
q_taken_mean:             -0.0159	return_mean:              -0.1765	return_std:                0.7464	target_mean:               0.1764
td_error_abs:              0.5399	test_battle_won_mean:      0.0000	test_ep_length_mean:      30.0000	test_return_mean:          0.0000
test_return_std:           0.0000	vdn extrinsic rewards:    -0.0156	vdn grad_norm:             0.4750	vdn hit_prob:              0.2479
vdn intrinsic rewards:     0.4285	vdn loss:                  0.0758	vdn prediction loss:       2.1427	vdn q_taken_mean:         -0.0684
vdn target_mean:           0.0077	vdn td_error_abs:          0.1909	
[INFO 05:35:11] my_main t_env: 2070 / 505000
[INFO 05:35:11] my_main Estimated time left: 29 minutes, 17 seconds. Time passed: 6 seconds
